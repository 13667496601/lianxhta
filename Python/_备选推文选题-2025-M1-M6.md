



# Python 练手数据文件汇总

- [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/)
  - [ucimlrepo package](https://github.com/uci-ml-repo/ucimlrepo)


# https://mml-book.com

- https://mml-book.com
- https://github.com/mml-book/mml-book.github.io
- PDF: https://mml-book.github.io/book/mml-book.pdf

# 使用quarto打造个人主页

- [creating-quarto-websites](https://ucsb-meds.github.io/creating-quarto-websites/)
  - [github](https://github.com/ucsb-meds/creating-quarto-websites/)

![20250612011340](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250612011340.png)

- [elizabethmcd.github.io](https://github.com/elizabethmcd/elizabethmcd.github.io) &rarr; [成品](https://elizabethmcdaniel.com/)

# 翻译+适当补充：假设检验与p值

- [Hypothesis testing in quant finance](https://reasonabledeviations.com/2021/06/17/hypothesis-testing-quant/)

在此基础上再加上 empirical p-value 的介绍。

# 

  - 我用 ChatGPT 写了一个版本，可以 [自此基础上](https://chatgpt.com/c/684a20e7-19cc-8005-b1ca-8eb20d29afed) 进行修改。

# 翻译+适当补充：如何阅读哲学书籍

- [probability-matching-brief-intro](https://naturalrationality.blogspot.com/2007/11/probability-matching-brief-intro.html)


# 翻译+适当补充-我是如何读书的

- [How I Read Books](https://reasonabledeviations.com/2022/01/24/reading-philosophy/)

- 翻译这篇推文。可以适当意译，以便符合中文读者的阅读习惯。
- 可以借助 AI 工具进行翻译，请务必进行人工校对与适当改写，避免语言过于机械。
- 在开头部分，介绍一下这篇推文的作者和背景。可以参考 [Reasonable Deviations](https://reasonabledeviations.com/) 网站的介绍，也可以搜索作者的个人主页。

# Man and machine: GPT for second brains

- [Man and machine: GPT for second brains](https://reasonabledeviations.com/2023/02/05/gpt-for-second-brain/)
- 还不确定

# Python明星包：PyPortfolioOpt-投资组合优化分析

- [PyPortfolioOpt 主页](https://pyportfolioopt.readthedocs.io/en/latest/index.html)
  - [github]()
  - [作者的 blog](https://reasonabledeviations.com/2020/03/19/rebuilding-pyportfolioopt/)

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250612081459.png)

![20250612082027](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250612082027.png)

> Source: [PyPortfolioOpt - Plot](https://pyportfolioopt.readthedocs.io/en/latest/Plotting.html)

![20250612082117](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250612082117.png)

> Source: [PyPortfolioOpt - Plot](https://pyportfolioopt.readthedocs.io/en/latest/Plotting.html)

## 应用实例

- [cookbook](https://github.com/robertmartin8/PyPortfolioOpt/tree/master/cookbook)
  - 里面放置了几个典型的 `.ipynb` 文件，展示了如何使用 `PyPortfolioOpt` 包进行投资组合优化分析。

# 809：Stata可视化：pheatplot-图示系数的显著性

写一篇推文，介绍这个命令的用法。

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250611232839.png)

## 安装

```stata
net install gr0099.pkg, all replace 
```

执行上述命令后，如下两份文件会自动下载到当前工作路径下：

```raw
online_supplement.pdf
pheatplot-examples.do
```

你可以使用 `shellout online_supplement.pdf` 命令打开 `online_supplement.pdf` 文件，也可以执行 `clickout` 命令，以便在屏幕上呈现上述文件。

# B808：论文精要-sfma-非参数稳健SFA模型

两篇推文的工作量：

- 写一篇中文精要，介绍这个方法的背景、模型设定、估计方法和应用场景。
  - 格式和要求，参见 [论文复现和中文精要类推文写作指南](https://file.lianxh.cn/KC/lianxh_TA_replication_Guide.pdf) (内附往期范例文档).
- 写一个 `.ipynb` 文件，讲义格式，内嵌 Python 代码和结果解读。(Python 环境配置，参见 [Python：安装和环境配置](https://book.lianxh.cn/ds/body/01_1_install-Python-Anocanda.html))


--- - --


Robust non-parametric frontier estimation

> Zheng, P., Worku, N., Bannick, M., Dielemann, J., Weaver, M., Murray, C., & Aravkin, A. (2024). Robust Nonparametric Stochastic Frontier Analysis (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2404.04301) (rep), [PDF](https://arxiv.org/pdf/2404.04301.pdf), [Google](<https://scholar.google.com/scholar?q=Robust Nonparametric Stochastic Frontier Analysis (Version 1)>). [github](https://github.com/ihmeuw-msca/sfma)

- sfma
  - `pip install sfma`
  - `from sfma import SFA`
  - The SFMA package is available for general public use through the Python package `sfma`, available at <https://github.com/ihmeuw-msca/sfma>.

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250610225636.png)

| Model  | Stochastic | Non-parametric | Specified Obs. SE | Outlier-Robust |
| :----- | :--------- | :------------- | :---------------- | :------------- |
| DEA    | x          | ✓              | x                 | x              |
| SFA    | ✓          | x              | x                 | x              |
| StoNED | ✓          | ✓              | x                 | x              |
| SFMA   | ✓          | ✓              | ✓                 | ✓              |

### sfma 的特点

The approach in this paper, dubbed SFMA, addresses three key aspects:

-   1. Nonparametric modeling of the frontier using splines
-   2. Detailed modeling of statistical errors, including reported sampling error, as well as unknown non-sampling error and inefficiencies
-   3. Automated outlier detection and removal.

To provide a robust software tool, we implement a customized optimization algorithm that exploits problem structure and performs a single unified analysis that determines outliers, estimates error statistics, and infers the spline coefficients of the frontier and other covariate multipliers of interest.

The SFMA approach can strongly influence our understanding and interpretation of the results, particularly for complex real datasets like those presented here: GDP vs life expectancy (LE), physician density vs universal health coverage (UHC), and nurse density vs health coverage. For these datasets, SFMA obtains helpful results, while a cross-section of tools available across Stata, R, and Python fall short: StoNED fails to converge, SFA and DEA return results that run counter to conventional wisdom in the field, as described below.

-   1. For LE vs. GDP, DEA shows no change in LE for different levels of GDP, while the SFA 'frontier' stays far below the upper bound of the data, and reports a very steep (almost vertical) increase in life expectancy at low levels of GDP per capita. The SFMA analysis suggests that LE increases gradually with GDP, albeit more at lowest levels of GDP than higher. That result is made possible due to the outlier-removal functionality available to SFMA.

-   2. For health coverage, the DEA analysis suggests that physicians have no effect on UHC above 10 physicians per 10,000 population, a clearly falsifiable conclusion. The SFA and SMFA analyses more plausibly show some benefit of more physicians; SFA gain fails to reach the upper limits of the data.


# B807：编程助手：Cursor - 为经管研究注入 AI 动力的代码编辑器

本文介绍基于人工智能技术的代码编辑器 Cursor，探讨它如何通过智能代码生成、即时代码问答、自动调试等先进功能，显著提升经管专业学生在 Stata、Python 和 R 环境下开展数据分析与实证研究的编程效率。

**应用场景展示**：

- 场景一：在网络上找到了一段复杂的 Stata 回归代码，学生难以快速理解。Cursor 可通过自然语言请求即时给出清晰解释，帮助学生准确理解代码逻辑。

- 场景二：使用 Cursor 快速生成 Python 数据清洗和可视化代码。只需用简单的自然语言描述需求，即可获得一整套高效、可直接运行的分析脚本。

参考资料：

- 官方网站：[Cursor](https://cursor.sh/)
- [Cursor AI 使用指南与实践示例](https://www.datacamp.com/tutorial/cursor-ai-code-editor)

---

# B806：翻译+扩充：Stata：pretrends-更严谨的平行趋势检验

请参考 GitHub 项目：[stata-pretrends](https://github.com/mcaceresb/stata-pretrends)，参阅相关论文，写一篇推文，介绍 `pretrends` 命令的理论基础和使用方法。

- 理论基础：[Roth (2022)](https://jonathandroth.github.io/assets/files/roth_pretrends_testing.pdf)
- 介绍应用时，务必W花点篇幅，介绍 [He and Wang (2017)](https://www.aeaweb.org/articles?id=10.1257/app.20160079) 一文的故事背景和数据情况。 

The `pretrends` package provides tools for power calculations for pre-trends tests, and visualization of possible violations of parallel trends. Calculations are based on [Roth (2022)](https://jonathandroth.github.io/assets/files/roth_pretrends_testing.pdf). This is the Stata version of the [R package of the same name](https://github.com/jonathandroth/pretrends). (Please cite the paper if you enjoy the package!)

温馨提示：

- 可以借助 AI 工具进行翻译，但务必手动运行全部代码，确保结果准确。
- 完成翻译后，请务必进行人工校对与适当改写，避免语言过于机械。
- 参考文献可以用 `getiref` 命令自动获取。 

---

# B805：Github 项目推介：MinerU

**项目简介**：MinerU 是一款开源工具，可精准地将 PDF 格式的学术文献（尤其是英文期刊论文）转换为 Markdown 或 JSON 格式，识别精确度高，特别适合处理论文中的版式、表格、公式和图片等复杂元素，大幅提升研究者的文献数字化管理效率。

**应用演示**：

以经济学顶级期刊 PDF 论文为例，使用 MinerU 的简单命令行工具演示转换过程，直观展示其在提取表格、公式方面的卓越表现。

- GitHub 项目链接：[MinerU](https://github.com/opendatalab/MinerU)

---

# B804：双重机器学习速通指南

本文系统地讲解如何在 Stata 中实现双重机器学习（Double Machine Learning）。

**撰写要点**：

1. 明确演示在 Stata 中配置 Python 环境的完整步骤，解决用户常见的难点。
2. 提供可完全复现的经济学实证论文示例，包含使用 `ddml` 命令从基础回归到内生性处理、稳健性测试、机制分析及异质性检验等全套流程。

参考资料：[双重机器学习官方网站](https://statalasso.github.io/)

---

# B803：EconML：因果机器学习的实现流程

本文介绍用于因果推断的 Python 库 EconML。相比于传统在 Stata 环境中实现的 DML 方法，EconML 具备更高的灵活性和扩展性，成为双重机器学习研究的理想工具。

**突出展示的进阶应用**：

- 元学习器（Meta-Learners）的应用
- 因果森林（Causal Forests）方法
- 深度工具变量（Deep IV）技术

参考链接：

- [EconML 官方文档](https://econml.azurewebsites.net/index.html)
- GitHub 项目：[EconML](https://github.com/microsoft/EconML)

---

> `2025/6/11 19:49`


# B802：Python 仓库介绍：skfolio

- https://github.com/skfolio/skfolio
- [website](https://skfolio.org/)

## 1. skfolio 的定位与主要功能

`skfolio` 是一个专为 **投资组合优化**（portfolio optimization）、**绩效评估** 和 **风险分析**设计的 Python 包。它灵感来源于 `scikit-learn` 的 API 规范，兼容 `pandas` 和 `numpy`，支持与机器学习管道集成。其主要目标是让用户能够方便地进行多资产投资组合建模、优化、回测和分析。

主要特点包括：

* **投资组合建模**：提供多种投资组合模型（如均值-方差、Black-Litterman、风险平价等）和优化器。
* **集成机器学习管道**：支持与 scikit-learn 流水线（pipeline）无缝集成，可结合特征工程、时间序列预测等机器学习流程。
* **丰富的风险/收益指标**：内置多种投资组合绩效评估和风险度量工具（如夏普比率、索提诺比率、最大回撤等）。
* **自动化多资产回测**：支持资产收益率输入，自动执行优化、权重分配及绩效分析。

## 2. 安装方法

```bash
pip install skfolio
```

## 3. 基本使用流程

### 3.1 数据准备

通常需要一个多资产的收益率时间序列（可以是 DataFrame 格式，每列为一个资产）。

```python
import pandas as pd
returns = pd.read_csv('your_returns.csv', index_col=0, parse_dates=True)
# 每一列为不同资产的日收益率
```

### 3.2 投资组合模型与优化

以经典均值-方差（Mean-Variance）模型为例：

```python
from skfolio import MeanVariance, PortfolioOptimizer

# 创建一个均值-方差模型
model = MeanVariance()

# 创建优化器（最大化夏普比率）
optimizer = PortfolioOptimizer(model=model, objective="sharpe")

# 拟合优化器并获得最优投资组合
optimizer.fit(returns)
optimal_portfolio = optimizer.get_optimal_portfolio()
print(optimal_portfolio.weights)  # 输出各资产权重
```

### 3.3 绩效评估与风险指标

```python
from skfolio.metrics import sharpe_ratio, max_drawdown

# 直接调用绩效指标
sr = sharpe_ratio(optimal_portfolio)
md = max_drawdown(optimal_portfolio)
print(f"Sharpe Ratio: {sr}, Max Drawdown: {md}")
```

### 3.4 与机器学习管道集成

`skfolio` 支持与 scikit-learn 兼容的流水线，比如结合特征选择或回归预测模型：

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from skfolio import MeanVariance, PortfolioOptimizer

pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('optimizer', PortfolioOptimizer(model=MeanVariance(), objective="sharpe"))
])

pipe.fit(returns)
```

## 4. 支持的主要模型与功能

* 均值-方差模型（Mean-Variance, Markowitz）
* Black-Litterman 模型
* 风险平价（Risk Parity）
* 等权重（Equal Weight）
* 多种目标函数（最大化夏普比率、最小化方差、目标收益、目标风险等）
* 约束条件设置（如最大/最小持仓，行业暴露约束等）
* 时间序列回测与可视化

## 5. 与同类包的对比

| 包名           | 优势                                             | 劣势                                    |
| -------------- | ------------------------------------------------ | --------------------------------------- |
| skfolio        | sklearn 风格，API 友好，机器学习集成好，约束丰富 | 功能较新，社区资料有限                  |
| PyPortfolioOpt | 经典投资组合优化全，文档多                       | 主要偏向 Markowitz 和 Black-Litterman   |
| bt             | 强大的回测系统，支持复杂策略设计                 | 学习曲线略陡峭，投资组合建模灵活性一般  |
| riskfolio-lib  | 风险分散策略丰富，支持多种风险模型               | 机器学习集成弱，API 不如 skfolio 现代化 |

## 6. 官方资料与文档

* [skfolio 官方文档](https://skfolio.org/)
* [skfolio GitHub](https://github.com/skfolio/skfolio)

## 7. 参考文献

如需系统阅读投资组合优化和相关理论，推荐以下经典文献：

* Markowitz, H. (1952). Portfolio Selection. The Journal of Finance, 7(1), 77–91. [Link](https://doi.org/10.2307/2975974), [PDF](http://sci-hub.ren/10.2307/2975974), [Google](https://scholar.google.com/scholar?q=Portfolio+Selection+Markowitz)





# B801：新书推介：大语言模型精要

- Jay Alammar and Maarten Grootendorst, 2024, Hands-On Large Language Models. O'Reilly. [-Link-](https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/), [website](https://www.llm-book.com/)
  - [github](https://github.com/HandsOnLLM/Hands-On-Large-Language-Models), [github-中文](https://github.com/bbruceyuan/Hands-On-Large-Language-Models-CN) 
  - [中文推介](https://blog.csdn.net/2301_81888214/article/details/145735234)


# B800：翻译：LLM-Agents简介

- Maarten Grootendorst, 2024. A Visual Guide to LLM Agents: Exploring the main components of Single- and Multi-Agents. [-Link-](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-llm-agents), [中文](https://mp.weixin.qq.com/s/QFJyS0TUCv-TT39isRLu3w)


# B799：翻译：词向量的原理

[Jay Alammar](https://jalammar.github.io/), The Illustrated Word2vec, [-Link-](<https://jalammar.github.io/illustrated-word2vec/>), [中文版](https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651669277&idx=2&sn=bc8f0590f9e340c1f1359982726c5a30&chksm=bd4c648e8a3bed9817f30c5a512e79fe0cc6fbc58544f97c857c30b120e76508fef37cae49bc&scene=0&xtrack=1#rd)

# B798：bnlearn-基于贝叶斯的因果关系自动发掘工具

`bnlearn` is Python package for causal discovery by learning the graphical structure of Bayesian networks, parameter learning, inference, and sampling methods. Because probabilistic graphical models can be difficult to use, `Bnlearn` contains the most-wanted pipelines. Navigate to [API documentations](https://erdogant.github.io/bnlearn/) for more detailed information.

- [website](https://erdogant.github.io/bnlearn/pages/html/index.html)
- [github](https://github.com/erdogant/bnlearn)

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250530003653.png)

### Key Pipelines

| Feature | Description |
| --- |  --- |
| [**Causal Discovery / Structure Learning**](https://erdogant.github.io/bnlearn/pages/html/Structure%20learning.html) | Learn the model structure from data or with expert knowledge. |
| --- |  --- |
| [**Parameter Learning**](https://erdogant.github.io/bnlearn/pages/html/Parameter%20learning.html) | Estimate model parameters (e.g., conditional probability distributions) from observed data. |
| [**Causal Inference**](https://pgmpy.org/examples/Causal%20Inference.html) | Compute interventional and counterfactual distributions using do-calculus. |
| [**Generate Synthetic Data**](https://erdogant.github.io/bnlearn/pages/html/Sampling.html) | Generate synthetic data. |
| [**Discretize Data**](https://erdogant.github.io/bnlearn/pages/html/Discretizing.html) | Discretize continuous datasets. |


### Resources and Links

-   **Example Notebooks:** [Examples](https://erdogant.github.io/bnlearn/pages/html/Documentation.html#google-colab-notebooks)
-   **Blog Posts:** [Medium](https://erdogant.medium.com/)
-   **Documentation:** [Website](https://erdogant.github.io/bnlearn)

# B797：Python包：distfit-分布拟合

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250530002953.png)

写一篇推文，介绍 Python 中的 distfit 包，并在推文中插入一些简单的例子，来展示这个包的一些独特的功能。

- [distfit 主页](https://erdogant.github.io/distfit/pages/html/index.html)
  - [github](https://github.com/erdogant/distfit)

### Key Features

| Feature | Description |
| --- |  --- |
| [**Parametric Fitting**](https://erdogant.github.io/distfit/pages/html/Parametric.html) | Fit distributions on empirical data X. |
| --- |  --- |
| [**Non-Parametric Fitting**](https://erdogant.github.io/distfit/pages/html/Quantile.html) | Fit distributions on empirical data X using non-parametric approaches (quantile, percentiles). |
| [**Discrete Fitting**](https://erdogant.github.io/distfit/pages/html/Discrete.html) | Fit distributions on empirical data X using binomial distribution. |
| [**predict**](https://erdogant.github.io/distfit/pages/html/Functions.html#module-distfit.distfit.distfit.predict) | Compute probabilities for response variables y. |
| [**Generate Synthetic Data**](https://erdogant.github.io/distfit/pages/html/Generate.html) | Generate synthetic data. |
| [**Plots**](https://erdogant.github.io/distfit/pages/html/Plots.html) | Varoius plotting functionalities. |

### Resources and Links

-   **Example Notebooks:** [Examples](https://erdogant.github.io/distfit/pages/html/Documentation.html)
-   **Blog Posts:** [Medium](https://erdogant.github.io/distfit/pages/html/Documentation.html#medium-blog)
-   **Documentation:** [Website](https://erdogant.github.io/distfit)



# B796：marker：快速将PDF表格转换为Markdown或JSON数据

- [github](https://github.com/vikParuchuri/marker)

Marker converts documents to markdown, JSON, and HTML quickly and accurately.

-   Converts PDF, image, PPTX, DOCX, XLSX, HTML, EPUB files in all languages
-   Does structured extraction, given a JSON schema (beta)
-   Formats tables, forms, equations, inline math, links, references, and code blocks
-   Extracts and saves images
-   Removes headers/footers/other artifacts
-   Extensible with your own formatting and logic
-   Optionally boost accuracy with LLMs
-   Works on GPU, CPU, or MPS

## Performance


![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250530101756.png)

Marker benchmarks favorably compared to cloud services like Llamaparse and Mathpix, as well as other open source tools.

The above results are running single PDF pages serially. Marker is significantly faster when running in batch mode, with a projected throughput of 122 pages/second on an H100 (.18 seconds per page across 22 processes).

As you can see, the use\_llm mode offers higher accuracy than marker or gemini alone.

## Examples


| PDF | File type | Markdown | JSON |
| --- |  --- |  --- |  --- |
| [Think Python](https://greenteapress.com/thinkpython/thinkpython.pdf) | Textbook | [View](https://github.com/VikParuchuri/marker/blob/master/data/examples/markdown/thinkpython/thinkpython.md) | [View](https://github.com/VikParuchuri/marker/blob/master/data/examples/json/thinkpython.json) |
| [Switch Transformers](https://arxiv.org/pdf/2101.03961.pdf) | arXiv paper | [View](https://github.com/VikParuchuri/marker/blob/master/data/examples/markdown/switch_transformers/switch_trans.md) | [View](https://github.com/VikParuchuri/marker/blob/master/data/examples/json/switch_trans.json) |
| [Multi-column CNN](https://arxiv.org/pdf/1804.07821.pdf) | arXiv paper | [View](https://github.com/VikParuchuri/marker/blob/master/data/examples/markdown/multicolcnn/multicolcnn.md) | [View](https://github.com/VikParuchuri/marker/blob/master/data/examples/json/multicolcnn.json) |

## Installation

You'll need python 3.10+ and PyTorch. You may need to install the CPU version of torch first if you're not using a Mac or a GPU machine. See [here](https://pytorch.org/get-started/locally/) for more details.

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250530173405.png)

复制上图生成的代码，通过命令行运行：

- 按快捷键 Win+R，输入 `cmd`，打开命令行窗口
- 贴入 `pip3 install torch torchvision torchaudio` 命令。

然后，使用如下命令安装 `marker` 包:

```
pip install marker-pdf
```

If you want to use marker on documents other than PDFs, you will need to install additional dependencies with:

```
pip install marker-pdf[full]
```


# B795：推文+小视频：英文PDF文档转中文

- 任务 1：写一篇推文介绍如何使用 <https://pdf2zh.com/> 这个在线网站，快速将英文 PDF 翻译为中文版本。
  - 关键：自己亲自操作，将遇到的各种注意事项写在推文中。

- 任务 2：以推文为基础，录制一个 2-3mins 的小视频，随后通过连享会的视频号发布。

- 网站：https://pdf2zh.com/  
  - [github](https://github.com/Byaidu/PDFMathTranslate)
  


# B794：公开API资源汇总

Try Public APIs for free

写一篇推文，介绍各类公开 API 资源

- https://github.com/public-apis/public-apis




# B793：Stata：biastest-不同模型间系数差异检验

Guliyev, H. (2025). biastest: Testing parameter equality across different models in Stata (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2502.15049) (rep), [PDF](https://arxiv.org/pdf/2502.15049.pdf), [Google](<https://scholar.google.com/scholar?q=biastest: Testing parameter equality across different models in Stata (Version 1)>).

安装：

```stata
ssc install biastest

help biastest
```

可以根据帮助文件写推文，也可以到作者的主页，github，以及 google 上搜索相关资料进行补充。



# B792：Python 包介绍：akshare

- akshare (python 包)：<https://akshare.akfamily.xyz/>
- aktools (通用): <https://aktools.akfamily.xyz/>

要提供可以实操的 Python 代码。所有代码必须在 Python 中测试通过。

最好建立一个 .ipynb 文件，里面包含如下内容：
# akshare 简介
`akshare` 是一个开源的 Python 库，旨在为用户提供便捷的金融数据获取和分析功能。它支持多种数据源，包括股票、期货、外汇、宏观经济等，用户可以通过简单的 API 调用获取实时或历史数据。
# akshare 的主要功能
- **数据获取**：支持股票、期货、外汇、宏观经济等多种金融数据的获取。
- **数据分析**：提供多种数据处理和分析工具，包括技术指标计算、数据可视化等。
- **多数据源支持**：可以从多个数据源获取数据，包括新浪财经、网易财经、东方财富等。
- **易用性**：提供简单易用的 API 接口，用户无需复杂的配置即可使用。
- **社区支持**：拥有活跃的社区和文档，用户可以方便地获取帮助和分享经验。


# B791：数据分析常用提示词梳理

参考：

- [AI Prompts for Data Analysis](https://www.analyticshacker.com/analytics-resources/ai-prompts-for-data-analysis)
- [33 AI Prompts for Data Analysis
Examples for ChatGPT, Claude, Gemini and other LLMs](https://promptdrive.ai/ai-prompts-data-analysis/)
- YouTube 视频：[Prompt Engineering for Data Analysis (Python, Pandas, Chat GPT)](https://youtu.be/uuprB1LpT8Y?si=r0hdXwB7dUxQEiCH)



# B790：如何组织AI提示词工作流程

How To Organize AI Prompt Workflows

参考如下推文的结构，写一篇针对经管专业学生的推文。你可以记住ai把如下推文的链接或者是内容梳理出来发给ai，让他仿照这个写一个针对经管学生的。如果不太清楚提示词怎么写，可以先列个提纲，然后找我来讨论。

- [How To Organize AI Prompt Workflows](https://promptdrive.ai/how-to-organize-ai-prompt-workflows/)

# B789：编程助手：Windsurf Plugin

备选题目： Coedium 还是 Copilot？编程助手如何选？

自行查阅资料，写一篇推文介绍这两个编程助手的区别和优缺点。

以下是我收集到的一些资料：

- Karl Esi, 2024, Blog, [Why Use Codeium over GitHub Copilot](https://dev.to/thekarlesi/why-use-codeium-over-github-copilot-491e)
- [Windsurf Plugin (formerly Codeium)](https://marketplace.visualstudio.com/items?itemName=Codeium.codeium)
  - 里面的动图可以直接拿来用

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250515170341.png)

![Windsurf Plugin (formerly Codeium)](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250515164601.png)

> 设定密匙 token

1. In VSCode, open the Command Palette (**Ctrl/Cmd + Shift + P**), type Windsurf: `Provide Authentication Token`, and hit Enter.
2. Paste your token from step 1 and hit **Enter**.

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250515165916.png)


> Once the usage limit is reached, Cascade can continue to be used with the Cascade Base model. To continue using premium models, upgrade your plan.

# B788：Python：期权定价公式及实现

以这篇 Blog 为基础，写一篇推文介绍期权定价公式及其 Python 实现。

- [Binomial Trees in the Finance Toolkit](https://www.jeroenbouma.com/articles/binomial-trees)


# B787：ylearn：轻松实现因果分析的Python包

写一篇推文，介绍 `ylearn` 包的主要功能和使用方法。主要基于 [ylearn 简介](https://github.com/DataCanvasIO/YLearn/blob/main/README_zh_CN.md)

参考资料：

- 中文：<https://ylearn.readthedocs.io/zh-cn/latest/>
- Pipy: <https://pypi.org/project/ylearn/>

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250611104159.png)

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250611104354.png)

先介绍 `ylearn` 包的主要功能和特点，然后给出一个简单的使用示例，最后可以提及一些应用场景或优势。

推文中展示的 Python 实例，务必在 Jupyter Notebook 中运行通过，确保代码可执行。

# B786：HyperTS：端到端的时间序列分析工具

Xiaojing Zhang，Haifeng Wu，Jian Yang. HyperTS: A Full-Pipeline Automated Time Series Analysis Toolkit. https://github.com/DataCanvasIO/HyperTS. 2022. Version 0.2.x.

基于 <https://github.com/DataCanvasIO/HyperTS/blob/main/README_zh_CN.md> 写一篇推文介绍 `HyperTS` 包的主要功能和使用方法。[Examples](https://github.com/DataCanvasIO/HyperTS/tree/main/examples/zh_CN) 中提供了很多 .ipynb 文件，可以直接在 Jupyter Notebook 中运行。

# B785：FinanceDatabase：Github公开数据仓库简介

写一篇推文介绍这个仓库：[Github - JerBouma/FinanceDatabase](https://github.com/JerBouma/FinanceDatabase)，[项目主页](https://www.jeroenbouma.com/projects/financedatabase)

- 可以借助 AI
- 写作过程中务必亲自在 Python 中操作一下，至少测试其中 3-5 个接口的数据获取。然后选取 1-2 个有特色的，放在一个 Section 中加以介绍 (附上完整的 Python 代码，可以借助 AI 生成，但一定要自己亲测能跑通)
  - [项目主页](https://www.jeroenbouma.com/projects/financedatabase) 的 **Projects** 和 **Usage** 部分都可以参考

## 简介

**This database tries to solve that**. It features 300.000+ symbols containing Equities, ETFs, Funds, Indices, Currencies, Cryptocurrencies and Money Markets. It therefore allows you to obtain a broad overview of sectors, industries, types of investments and much more.

The aim of this database is explicitly *not* to provide up-to-date fundamentals or stock data as those can be obtained with ease (with the help of this database) by using the [Finance Toolkit](https://github.com/JerBouma/FinanceToolkit). Instead, it gives insights into the products that exist in each country, industry and sector and gives the most essential information about each product. With this information, you can analyse specific areas of the financial world and/or find a product that is hard to find. See for examples on how you can combine this database, and the earlier mentioned packages the section [Usage](https://github.com/JerBouma/FinanceDatabase#usage). 

Some key statistics of the database:

| Product          | Quantity | Sectors | Industries | Countries |
|------------------|----------|---------|------------|-----------|
| Equities         | 158,429  | 12      | 63         | 111       |
| ETFs             | 36,786   | 295     | 22         | 111       |
| Funds            | 57,881   | 1,541   | 52         | 111       |

| Product          | Quantity | Category          |
|------------------|----------|-------------------|
| Currencies       | 2,556    | 175 Currencies    |
| Cryptocurrencies | 3,367    | 352 Cryptocurrencies |
| Indices          | 91,183   | 64 Exchanges      |
| Money Markets    | 1,367    | 3 Exchanges       |

# B784：论文推介：贝叶斯SFA

Wei, Z., Choy, S. T. B., Wang, T., & Zhu, X. (2025). Bayesian stochastic frontier models under the skew-normal half-normal settings. Journal of Productivity Analysis. [Link](https://doi.org/10.1007/s11123-025-00757-3), [PDF](https://link.springer.com/content/pdf/10.1007/s11123-025-00757-3.pdf), [Google](<https://scholar.google.com/scholar?q=Bayesian stochastic frontier models under the skew-normal half-normal settings>). [github](https://github.com/ZWeiSTAT/BayesianSNSFM.git) (R codes, Data, Jupyter Notebook)

- 介绍论文的核心思想、适用场景和假设条件
- 模型设定和估计方法简介
- R 语言实现 [github](https://github.com/ZWeiSTAT/BayesianSNSFM.git) (R codes, Data, Jupyter Notebook) 

> Note: 我用 ChatGPT 生成了一个大概的提纲，你可以在此基础上进行修改和完善。[点击查看 B784-BayesSFA.md](https://github.com/arlionn/lianxhta/blob/main/sample/B784-BayesSFA.md)

----

> `2025/5/12 15:07`

# B783：开心Python：手绘风格的数据可视化

**任务：** 根据如下资料写一篇推文介绍如何使用 Python 来实现手绘风格的数据可视化。

> 你可以在 [ChatGPT 对话](https://chatgpt.com/share/6820d613-a638-8005-bc11-1ac6aae9b5f5) 基础上继续追问，形成推文。但一定要在 Python 中使用 jupyter notebook 来实现，自己生成图形插入文中。这样才能确保我们提供的代码都是可以执行的。


--- - --


## 简介

适合于商业展示，比较轻松的小组展示等。

## 使用 matplotlib 扩展包

![20250512003110](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250512003110.png)

![20250512001726](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250512001726.png)

- [matplotlib - 手绘风格的图形](https://matplotlib.org/stable/gallery/showcase/xkcd.html#sphx-glr-gallery-showcase-xkcd-py)
- [How To Make Hand-Drawn Style Plots In Python](https://medium.com/geekculture/how-to-make-hand-drawn-style-plots-in-python-709693f6877b)

- [matplotlib.pyplot.xkcd](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.xkcd.html)

```python
with plt.xkcd():
    # This figure will be in XKCD-style
    fig1 = plt.figure()
    # ...

# This figure will be in regular style
fig2 = plt.figure()
```

<br>
<br>

<br>
<br>
<br>
<br>
## 使用 py-roughviz/pygal 扩展包

![20250512001837](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250512001837.png)

- [上图对应的推文](https://medium.com/@nick-tan/want-to-get-away-from-the-standard-looks-of-the-charts-or-graphs-generated-by-matplotlib-and-cbdd7baaeae)

Want to get away from the "standard" looks of the charts or graphs generated by Matplotlib and Seaborn?

Here are three alternative visualization packages that offer **fun**, **playful**, and **unconventional** visualization styles:
- [py-roughviz](https://github.com/charlesdong1991/py-roughviz): Python 封装的 RoughViz.js，支持手绘风格的可视化。
- [pygal](http://www.pygal.org/en/stable/): 简洁优雅的 Python 图表库，支持 SVG 输出和多种图表类型。
- [cutecharts](https://github.com/cutecharts/cutecharts.py): 轻量级、手绘风格的 Python 可视化库，适合快速生成有趣的图表。

## 使用 cutecharts 扩展包

- [github](https://github.com/cutecharts/cutecharts.py)

![20250512002352](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250512002352.png)

- [Make the cutest chart in Python -visualize your data with hand-drawn charts](https://towardsdatascience.com/make-the-cutest-chart-in-python-visualize-your-data-with-hand-drawn-charts-f21157f76b4b/)


# B782：UCINET：社会网络分析利器介绍
- [UCINET](https://sites.google.com/site/ucinetsoftware/home)
  - [UCINET 6 for Windows](https://sites.google.com/site/ucinetsoftware/home/ucinet-6-for-windows)
  - [NetDraw](https://sites.google.com/site/netdrawsoftware/)
  - [UCINET 6 for Windows Manual](https://sites.google.com/site/ucinetsoftware/home/ucinet-6-for-windows/manual)
  - [NetDraw Manual](https://sites.google.com/site/netdrawsoftware/manual)
  - [UCINET 6 for Windows Tutorial](https://sites.google.com/site/ucinetsoftware/home/ucinet-6-for-windows/tutorial)

# B781：PNET：社会网络分析利器介绍

- [PNET 官网](https://www.melnet.org.au/pnet/)
  - [PNet User Manual](https://www.melnet.org.au/s/PNetManual.pdf) 
  - [MPNet User Manual](https://www.melnet.org.au/s/MPNetManual.pdf)
  - [MPNet Tutorial](https://static1.squarespace.com/static/57a1436215d5dbbcd2031828/t/629422ef5c17c102ff150f96/1653875458648/MPNet+tutorial.pdf)


# B780：Python：金融数据库-FinanceDatabase

写一篇推文介绍这个仓库和 Python 包。并在推文中插入几个简单的例子，来展示这个包的一些独特的功能。

主要参考文档是其 [website](https://www.jeroenbouma.com/projects/financedatabase)。

- github: https://github.com/JerBouma/FinanceDatabase
- Website: https://www.jeroenbouma.com/projects/financedatabase
**This database tries to solve that**. It features 300.000+ symbols containing Equities, ETFs, Funds, Indices, Currencies, Cryptocurrencies and Money Markets. It therefore allows you to obtain a broad overview of sectors, industries, types of investments and much more.

The aim of this database is explicitly *not* to provide up-to-date fundamentals or stock data as those can be obtained with ease (with the help of this database) by using the [Finance Toolkit 🛠️](https://github.com/JerBouma/FinanceToolkit). Instead, it gives insights into the products that exist in each country, industry and sector and gives the most essential information about each product. With this information, you can analyse specific areas of the financial world and/or find a product that is hard to find. See for examples on how you can combine this database, and the earlier mentioned packages the section [Usage](https://github.com/JerBouma/FinanceDatabase#usage).

# B779：Python 扩展包：Freqtrade 介绍

- Freqtrade is a free and open source crypto trading bot written in Python. It is designed to support all major exchanges and be controlled via Telegram or webUI. It contains backtesting, plotting and money management tools as well as strategy optimization by machine learning.

# B778：金融中的机器学习仓库

写一篇推文介绍这个仓库，并列举一些有趣的项目。最好能找到 3-5 篇使用该仓库扩展包的论文，列出完整的引文信息，以便读者了解该扩展包在学术文献中的用途。 

- [financial-machine-learning](https://github.com/firmai/financial-machine-learning)
  - 列示了上百个金融分析的仓库和项目
  - Fork 这个仓库，然后把 Wiki 中的仓库列表整理成一篇推文


----

> `2025/4/6 9:13`

# B777：推介：经济学家的深度学习

介绍这篇论文的核心观点，以及文中提及的主要深度学习方法。

- Melissa Dell. "Deep Learning for Economists." *Journal of Economic Literature*, forthcoming [Paper](https://econdl.github.io/redirects/publications/econdl)

**重点介绍作者提供的这个网站**：<https://econdl.github.io/>
- [Packages](https://econdl.github.io/packages.html), [Datasets](https://econdl.github.io/datasets.html)


# B776：AI助力：基于大语言模型的研究假设论证

- Ludwig, J., & Mullainathan, S. (2024). Machine Learning as a Tool for Hypothesis Generation. The Quarterly Journal of Economics, 139(2), 751–827. [Link](https://doi.org/10.1093/qje/qjad055) (rep), [PDF](https://bpb-us-w2.wpmucdn.com/voices.uchicago.edu/dist/3/1161/files/2024/02/QJE-machine-learning-for-hypothesis-generation-202461-8f8c19422434d44d.pdf), [Google](<https://scholar.google.com/scholar?q=Machine Learning as a Tool for Hypothesis Generation>).
- Batista, Rafael and Ross, James, Words that Work: Using Language to Generate Hypotheses (July 01, 2024). Available at SSRN: https://ssrn.com/abstract=4926398 or http://dx.doi.org/10.2139/ssrn.4926398 [-PDF-](https://download.ssrn.com/2024/9/9/4926398.pdf?response-content-disposition=inline&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEH4aCXVzLWVhc3QtMSJGMEQCIDILb74QncyuE%2B42i9xf%2BaxvsMECsst7t7uhMbItW73LAiBcnjJzWocv5%2BXlRr%2Fmq4h2z%2FcLz%2B14pFhwnGyh81WW%2ByrGBQjX%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAQaDDMwODQ3NTMwMTI1NyIMNgLD9Vt%2BLZqZWj66KpoFO0KAyg2Wek2gSHmYOsnNH%2F8MszEixWa4Nq7cMglkzJCUR6uAYSFmeV2CQhMpZKP2%2Bahc%2BTwfTOQeMKuFj%2BLkRnt477JIBmFe80Rw56Bw9dFd6vBgbec%2F814fgUS6U%2Fb%2ByuCj6ij%2Bemp6lnfpMoW7geqicd7SrWyW3F7UTwjSRvw6HxUvYmR%2B5TGNz1w8DxHGg7tPBwcNVqf8McuBxFXOngkBVOHRBDGea1cR5lDkhhYj65ZC45UsVd1oVL4VBpGgPMLxrOvV3JvFzlpI4RwxYnylag8dKbXd%2BA6cTubHulW1z658QPYPO8dEKMGeKzvdy3%2FcmQ%2BjwNdmjt7PZIv64I4j9hmdW7S42M8WRxj%2FSO%2B4S%2BLQ8Zgok%2B0lzT4fh8b%2B%2B%2FRsW47S3uA3PltYjZ3qEzw1bBIADrZJJlS%2BYCspDu34Lr9HIwEpjd7%2FixbqOCUmla%2BpWn%2BJvMBbuCx1BGBQ%2BNmLfaHW93ACLeMAJ%2Brzw%2Bt4%2BebL%2B4xoMkDgU30GwRZ0q4%2BYoRBzAHe3aFhXhdn3xDtzjSzCB%2BDhXQMNg2mWYPrJUxuIcTgQABOU99BHzU2KrEThFF8jdY0HEGE8gL5o5Sg845fN0uzEN%2B0QyZyvSM8MkgkXULfMB20JHxdUsKOkClMMYSWHtr%2Fkx%2FXFJmwmp9OKGnWiJYXLE8m55AcRBpNXJXs%2FngtEyMGP0rKbRgIk0yjmqYyzYj6wNr%2B1BsX8oqT%2F%2FqDNXKttXNa4970LsI%2F1YCnlsDCKi7VtWWhqaQwl4Vi7Cgpq%2BAgeZPscapn1kmOHkXZLTB2TPq7JwlVycQSk72rjTSJRbzmExIHllIe83uMIOTmfJiAWYi%2Bzar%2FK0Hcstik6jguowBY4rc65uEnVsdlnvv0jYt5QMIicgL8GOrIBKdJchzbumtXX5xb3f3eDTcxCHSXTB1%2B%2FuIxTniH50E1eCFQ0mvcIuoIn85E1lIvbRIWjyB9LJEfP9rFutg22pDqYBzpb8ha2MbNzGvb0oM4TbY50wbeBtYTyD38v1oQTGNJH0a0FCAWnQNSFdkIIYWc7i75yR33OWrvw2DwvThfZ%2B%2FWtJ6qoPQixlDZnA7tMgmm4rf658mkC3VBP6tyTyFKB6aBACFKD1zjQfU%2BJBBlNTg%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250323T145004Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAUPUUPRWE6TQSXMQN%2F20250323%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=1ef5040c9a576866c6cc92bc11c12b1175dfea662d9557288dc84204f953f0ba&abstractId=4926398)
  - 该文的附录提供了一些 Prompts





# B775：用AI协助生成研究假设：我的三组提示词

- Anna Young, 2024, Blog, I Use These 3 ChatGPT AI Prompts for Crafting Hypotheses, and the Results Blew My Mind!, [-Link-](https://medium.com/@yangyinjuan.zju/i-use-these-3-chatgpt-ai-prompts-for-crafting-hypotheses-and-the-results-blew-my-mind-8fd4cafef55b)
  - 按照作者撰写提示词的思路，写三个中文版本，并分别在 ChatGPT, DeepSeek 和豆包中测试
  - 最终形成一些些提示词的思路和大致要求

## 作者提供的提示词模板

- **Prompt 1**: Adopt the role of an academic researcher in [RESEARCH AREA]. Your task is to plan a clear and concise hypothesis that addresses a specific research question within this area. The hypothesis should be based on existing literature, theories, or frameworks relevant to [RESEARCH AREA]. It must be testable, either through empirical research methods or qualitative analysis, and should contribute to the existing body of knowledge by addressing a gap or challenging an existing assumption. Ensure your hypothesis is specific, measurable, achievable, relevant, and time-bound (SMART). Provide a brief explanation of the rationale behind your hypothesis, linking it to key concepts, theories, or previous studies in the field.
- **Prompt 2**: Determine how more evidence can be integrated into the essay [Insert essay topic] to strengthen the argument [Insert what you wish to prove through the essay].
- **Prompt 3**: Give me the most relevant theories, models, and commonly cited research on the topic [Insert topic name] for writing Hypotheses part of the [Insert what you wish to prove through the essay].



# B774：论文推介：如何利用大语言模型辅助生成因果推断的假设条件

- Cohrs, K.-H., Diaz, E., Sitokonstantinou, V., Varando, G., & Camps-Valls, G. (2025). Large language models for causal hypothesis generation in science. Machine Learning: Science and Technology, 6(1), 013001. [Link](https://doi.org/10.1088/2632-2153/ada47f), [PDF](https://iopscience.iop.org/article/10.1088/2632-2153/ada47f/pdf), [Google](<https://scholar.google.com/scholar?q=Large language models for causal hypothesis generation in science>).

# B773：翻译：大语言模型通俗简介

- Byeungchun Kwon, Taejin Park, Fernando Perez-Cruz and Phurichai Rungcharoenkitkul, 2024, Large language models: a primer for economists, [-Link-](https://www.bis.org/publ/qtrpdf/r_qt2412b.htm), [-PDF-](https://www.bis.org/publ/qtrpdf/r_qt2412b.pdf), [github](https://github.com/bis-med-it/LLM_Primer_for_Economists)


# B772：论文推介：AI与社会科学融合到什么程度了？

- Xu, R., Sun, Y., Ren, M., Guo, S., Pan, R., Lin, H., Sun, L., & Han, X. (2024). AI for social science and social science of AI: A Survey (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2401.11839) (rep), [PDF](https://arxiv.org/pdf/2401.11839.pdf), [Google](<https://scholar.google.com/scholar?q=AI for social science and social science of AI: A Survey (Version 1)>).
  - 介绍了 AI 在社科各个领域的应用情况



# B771：AI能胜任匿名评审工作吗？

从下文中抽取主要观点，进而提供一些使用 AI 来评审自己论文初稿的例子 (主要是收集/自己测试一些有用的 Prompts)

作者在附录中提供了很多 Prompts，可以翻译为中文后在 ChatGPT 中测试一下。

- Liang, W., Zhang, Y., Cao, H., Wang, B., Ding, D. Y., Yang, X., Vodrahalli, K., He, S., Smith, D. S., Yin, Y., Mcfarland, D. A., & Zou, J. (2024). Can Large Language Models Provide Useful Feedback on Research Papers? A Large-Scale Empirical Analysis. NEJM AI, 1(8). [Link](https://doi.org/10.1056/AIoa2400196), [PDF](https://arxiv.org/pdf/2310.01783), [Google](<https://scholar.google.com/scholar?q=Can Large Language Models Provide Useful Feedback on Research Papers? A Large-Scale Empirical Analysis>).

核心观点：
- 通过回顾性和前瞻性评估，我们发现 LLM 反馈与人工反馈之间存在大量重叠，并且用户对 LLM 反馈的实用性持积极看法。尽管人工专家评审应继续成为科学过程的基础，但 LLM 反馈可能会使研究人员受益，尤其是在无法及时获得专家反馈以及稿件准备的早期阶段。
- 总结这篇论文的其他重要观点

如下内容非常实用：
- Supplementary Figure 5. Schematic of the LLM scientific feedback generation system。重点介绍这里提供的 ③ Prompt。

## Prompt 1: sample

```
Your task now is to draft a high-quality review outline for a Nature family journal for a
submission titled <Title>:
‘‘‘
<Paper_content>
‘‘‘

======
Your task:
Compose a high-quality peer review of a paper submitted to a Nature family journal.
Start by "Review outline:".
And then:
"1. Significance and novelty"
"2. Potential reasons for acceptance"
"3. Potential reasons for rejection", List multiple key reasons. For each key reason, use
**>=2 sub bullet points** to further clarify and support your arguments in painstaking
details. Be as specific and detailed as possible.
"4. Suggestions for improvement", List multiple key suggestions. Be as specific and detailed
as possible.
Be thoughtful and constructive. Write Outlines only.
```

# B770：新书推荐：CausalML-book

写一篇推文介绍这本书，包括：
- 简介：作者简介，内容梗概
- 特色：强调 ML 和 AI 在因果推断中的作用，列举书中的内容安排来说明。比如，第一章讲解 OLS 时，重点强调了 FWL 定理，引入了交叉验证等估计方法 (这通常是机器学习课本中重点介绍的内容，传统计量教科书通常不涉及这部分内容)
- 课程配套资料：notebook，R 和 Python 代码支持，参见该书的 [Website](https://causalml-book.org/)


> CausalML-book   

- Chernozhukov, V. & Hansen, C. & Kallus, N. & Spindler, M. & Syrgkanis, V. (**2024**): Applied Causal Inference Powered by ML and AI. CausalML-book.org; arXiv:2403.02467. [-PDF-](https://arxiv.org/pdf/2403.02467)，[Website](https://causalml-book.org/)
  - 该书的 [Website](https://causalml-book.org/) 提供了各章的 PDF，codes Notebook (R and Python)

## 来自大牛的书评

> Joshua Angrist  

![20250324164635](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250324164635.png)

> Judea Pearl  

![20250324164814](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250324164814.png)


# B769：AI 工具推荐

自行搜索资料，整理一份相对完整的适用于学术研究的ai工具清单。

我们这篇推文只整理有关学术研究方面的，至于其他画画啊，生活方面的我们就不要涉及了。

参考资料：
- [全球AI网站汇总](https://github.com/xxxily/hello-ai/blob/main/home/navigation.md)
- [最新免费AI服务网站推荐](https://github.com/xxxily/hello-ai/blob/main/README-zh.md)


# B768：论文推介：如何论证因果关系？

- Garg, P., & Fetzer, T. (2025). Causal Claims in Economics (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2501.06873) (rep), [PDF](https://arxiv.org/pdf/2501.06873.pdf), [Google](<https://scholar.google.com/scholar?q=Causal Claims in Economics (Version 1)>).
  - [Short-Review](https://cepr.org/voxeu/columns/leveraging-large-language-models-large-scale-information-retrieval-economics)

推文重点：
- 各种因果推断方法的应用情况和趋势
- 不同研究主题和关键词的关注趋势
- 其它 (酌情确定)

![20250324154633](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250324154633.png)

> **Figure 4**: Proliferation of Empirical Methods Over Time in NBER and CEPR Working Papers   
> **Note**: This figure shows the proliferation of key empirical methods used in NBER and CEPR working papers over time: Difference-in-Differences (DiD), Instrumental Variables (IV), Randomized Controlled Trials (RCTs), Regression Discontinuity Design (RDD), Two-Way Fixed Effects (TWFE), Structural Estimation, Event Studies, Simulations, and Theoretical/Non-Empirical research. Each panel represents the proportion of papers utilizing one of these methods per year, with the $y$-axis showing the proportion of total papers and the $x$-axis indicating the year of publication. The data covers all NBER and CEPR working papers from 1980 to 2023. DiD has seen a significant increase since the 1980s, rising from around $4 \%$ to over $15 \%$ of papers in recent years, reflecting its growing importance in empirical research. IV methods have also increased steadily from approximately $2 \%$ to over $6 \%$ over the same period. RCTs and RDDs, while starting from near zero in the 1980s, have grown to over $7 \%$ and $2 \%$ respectively in recent years, indicating the rising feasibility and acceptance of experimental and quasi-experimental designs in economics. Conversely, the use of theoretical and non-empirical research has declined significantly, from around $20 \%$ in 1980 to under $10 \%$ in 2023, suggesting a shift towards empirical analysis in the discipline. The use of simulations has decreased from over $6 \%$ in 1980 to around $2-4 \%$ in recent years. These trends highlight the increasing emphasis on credible identification strategies and the evolution of empirical methods in economics.

![20250324154846](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250324154846.png)

> Figure 5: Cross-Sectional Breakdown of Empirical Methods by Field in NBER and CEPR Working
Papers   
> Note: This figure displays the cross-sectional distribution of nine empirical methods-Difference-in-Differences (DiD), Instrumental Variables (IV), Randomized Controlled Trials (RCTs), Regression Discontinuity Design (RDD), Event Studies, Simulations, Structural Estimation, Two-Way Fixed Effects (TWFE), and Theoretical/Non-Empirical research-across twelve fields in NBER and CEPR working papers. Each point represents the proportion of papers within a specific field that utilize a given method, with $95 \%$ confidence intervals depicted by error bars. The fields include Finance, Development, Labour, Public, Urban, Macroeconomics, Behavioral, Economic History, Econometrics, IO, Environmental, and Health. The plot highlights considerable variation in the adoption of empirical methods across fields. DiD is most commonly used in Health, Urban, and Labour, with over $21 \%$ of papers in Health, over $16 \%$ in Urban, and over $13 \%$ in Labour utilizing this method. RCTs are particularly prominent in Behavioral and Development, where they are used in over $20 \%$ and $11 \%$ of papers respectively, reflecting the feasibility of experimental interventions in these areas. Simulations and Structural methods are more prevalent in Macroeconomics and Econometrics, reflecting the need for complex theoretical modeling in these fields. Simulations account for over $6 \%$ of papers in Macroeconomics and over $6 \%$ in Econometrics. Structural methods are used in approximately 6\% of papers in Macroeconomics and over 5\% in Econometrics. Fields like Macroeconomics and Finance rely more on IV methods and simulations, with Macroeconomics having around 3\% of papers using IV methods and over $6 \%$ using simulations. Theoretical and non-empirical research remains significant in fields like Industrial Organization and Macroeconomics, with over $24 \%$ and $17 \%$ of papers respectively. These cross-sectional patterns reflect the methodological preferences specific to the research questions and data availability in each field, underscoring how different areas of economics adopt various empirical strategies to address their unique challenges.

![20250324155133](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250324155133.png)

> Figure 11: Top 5 Rising and Declining Nodes’ Eigenvector Centrality Over Time (Normalized)



# B767：IV：形形色色的 IV

> Wu, A., Kuang, K., Xiong, R., & Wu, F. (2022). Instrumental Variables in Causal Inference and Machine Learning: A Survey (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2212.05778) (rep), [PDF](https://arxiv.org/pdf/2212.05778.pdf), [Google](<https://scholar.google.com/scholar?q=Instrumental Variables in Causal Inference and Machine Learning: A Survey (Version 1)>).

> TABLE 1: Available Codes of Methods for Instrumental Variables and Causal Inference.

|           | IV-based Methods |                                                        |
| :-------: | :--------------: | :----------------------------------------------------: |
|  Method   |     Language     |                          Link                          |
|  DeepIV   |      python      |          https://github.com/jhartford/DeepIV           |
| KernelIV  |      matlab      |           https://github.com/r4hu1-5in9h/KIV           |
|  DualIV   |      matlab      |     https://github.com/krikamol/DualIV-NeurIPS2020     |
|   DFIV    |      python      |      https://github.com/liyuan9988/DeepFeatureIV       |
|  DeepGMM  |      python      |          https://github.com/CausalML/DeepGMM           |
|   AGMM    |      python      |      https://github.com/microsoft/AdversarialGMM       |
|   CBIV    |      python      |             https://github.com/anpwu/CB-IV             |
|  AutoIV   |      python      |          https://github.com/junkunyuan/AutoIV          |
|  econML   |      python      |          https://github.com/microsoft/EconML           |
| CausalDCD |      python      | https://github.com/anpwu/Awesome-Instrumental-Variable |


> 2025/4/5 23:42

# B766：AI助手系列：Paperpal

写一篇推文介绍这个工具。
- https://paperpal.com/
- https://www.editage.com/paperpal

## 要求
- 可以用 google 账号登录
- 可以在 Word 中安装插件
- 主要功能：可以搜索官网介绍文档，在线博客文章，Youtube 视频等资料来写
- 注意：所有写入推文中的内容一定要自己亲自测试过感受过，如果你因为设备或网络的原因不能够亲自测试，你可以邀请你的同学或朋友帮你测试。不能简单的当二道贩子，从别的地方翻译过来插到推文里。

## ChatGPT 给出的介绍

Paperpal 是由开科思（Cactus Communications）推出的一款专为科研人员设计的人工智能学术写作工具。它旨在通过提供语言编辑、文本改写与生成、投稿检查等功能，帮助研究人员提升英文论文的质量和发表成功率。

**主要功能：**

- 语言编辑：提供学术语境下的语言校正建议，检查语法、用词和格式一致性，确保文章表达准确流畅。
- AI 助写：协助作者改写句段、缩减篇幅，并生成投稿信、进度查询邮件等沟通素材，优化写作过程。
- 稿件查重：利用 Turnitin 技术检测文章重复率，标注相似内容，维护学术诚信。
- 投稿检查：根据期刊标准，对稿件进行语言和技术评估，提供改进建议，提升投稿质量。

**使用场景：**

- Paperpal 支持网页版、Word 插件和 Overleaf 插件等多种使用模式，方便用户在不同平台上进行学术写作和编辑。
- Paperpal 的技术内核由开科思独立研发，严格遵守学术出版伦理，确保用户数据的安全性和隐私性。

总体而言，Paperpal 通过集成多种智能功能，致力于为学术写作者提供高效、专业的写作辅助服务。



# B765：文献助手：Research Rabbit

> https://researchrabbitapp.com

介绍这个工具，内容上，覆盖这个视频中的内容：[5 Unbelievably Useful AI Tools For Research in 2025 (better than ChatGPT)](https://www.youtube.com/watch?v=wmQVdzBRnN4)

其他参考资料：

Research platform for discovering and visualizing both literature and scholars.
- [-PDF-](https://www.jcu.edu.au/__data/assets/pdf_file/0008/1958831/Research-Rabbit-Overview.pdf)
- [What is ResearchRabbit?](https://teaching.usask.ca/learning-technology/tools/researchrabbit.php)
- Youtube 视频：
  - [How To Use Research Rabbit - Effortlessly Explore Literature for FREE!](https://www.youtube.com/watch?v=phWqcGcxeE4)
  - [5 Unbelievably Useful AI Tools For Research in 2025 (better than ChatGPT)](https://www.youtube.com/watch?v=wmQVdzBRnN4)



# B764：翻译+改写：写代码的提示词Prompts

- [RimaBuilds/Master-coding-prompts-with-ChatGPT](https://github.com/RimaBuilds/Master-coding-prompts-with-ChatGPT)

**写作建议：**

1. Fork 这个仓库，然后打开 readme.md 的原始文档，复制后进行翻译即可。   
2. 注意：最终的博客文章中，不要包含任何表情符号。你可以使用 DeepSeek 等 AI 工具一次性去除所有表情符号。  
3. 提示词采用引用块格式：
   
   ```md
   > Prompt: xxx`
   ```

5. 你可以借助 AI 进行翻译，但要确保最终的中文版不要太生涩，需要自己改一下。 
6. 你可以酌情扩充或适当删减原文中的内容
7. 注意：务必在推文开头部分采用 「编者按：xxx」方式写明这篇推文的来源，以免引起版权纠纷。参见 刘正清, 2025, [被盯上的 EJ 论文：从被质疑到漂亮反击](https://www.lianxh.cn/details/1552.html)。


# B763：翻译+改写：DEV ChatGPT Prompts

- [PickleBoxer/dev-chatgpt-prompts](https://github.com/PickleBoxer/dev-chatgpt-prompts)

写作建议：

1. Fork 这个仓库，然后打开 readme.md 的原始文档，复制后进行翻译即可。   
2. 注意：最终的博客文章中，不要包含任何表情符号。你可以使用 DeepSeek 等 AI 工具一次性去除所有表情符号。  
3. 提示词采用引用块格式：
   
   ```md
   > Prompt: xxx`
   ```

5. 你可以借助 AI 进行翻译，但要确保最终的中文版不要太生涩，需要自己改一下。 
6. 你可以酌情扩充或适当删减原文中的内容
7. 注意：务必在推文开头部分采用 「编者按：xxx」方式写明这篇推文的来源，以免引起版权纠纷。参见 刘正清, 2025, [被盯上的 EJ 论文：从被质疑到漂亮反击](https://www.lianxh.cn/details/1552.html)。


# B762：如何借助 AI 高效完成文献综述

- 根据 Youtube 视频写一篇推文，介绍用于文献综述的 AI 工具。也可以结合类似视频中的内容。注意：推文中提及的工具一定是自己亲测过的工具。[The fastest way to do your literature review with AI](https://www.youtube.com/watch?v=O60Ha2woAZI)
- 可以酌情搜索其他资料补充进来
- 在写推文之前，务必亲自测一下视频里提到的ai工具。如果你不使用就来写这篇推文，那就属于欺骗，而且你写的时候其实也不会有什么感觉的。在你自己用的过程中有任何的障碍或者是你遇到的一些困难，你应该重点把它写在推文里，因为你如果遇到这些问题，其他第1次使用这个工具的用户也同样会遇到这些问题。
- 你可以进一步根据推文的内容录制一个视频 (15 min 左右)，可以算做一篇新的推文任务。



# B761：编写提示词（Prompt）的10条原则和15个建议

基于如下推文的内容，写一篇推文。当然他说的那些原则和建议也未必适合我们国内的这些用户。因为我们使用的ai工具会有一些限制，当然有一些国产的ai工具也不错。

所以在写作的过程中，你要根据国内的这些ai的特征，自己在搜索一些资料加上自己的一些体验。

你也可以借助ai工具来对下面这篇文章的内容进行翻译，但是翻译完以后你一定要自己手动的改一遍，因为有里边的一些术语是非常生硬的表述上也会显得像机器写的，所以你要适当的调整润色一下。

- Bozkurt, A. (2024). Tell Me Your Prompts and I Will Make Them True: The Alchemy of Prompt Engineering and Generative AI. Open Praxis, 16(2), 111–118. [Link](https://doi.org/10.55982/openpraxis.16.2.661), [PDF](https://openpraxis.org/articles/661/files/660d5a9fa8517.pdf), [Google](<https://scholar.google.com/scholar?q=Tell Me Your Prompts and I Will Make Them True: The Alchemy of Prompt Engineering and Generative AI>).
  - In this regard, this paper introduces 10 principles and 15 strategies that refer to ‘Prompt Engineering for Gen[i]erative AI Framework’ to unleash your prompts and, metaphorically, make your wishes true. 

# B760：ChatGPT助手系列：CClaRA-Causal Claims Research Assistant

> <https://www.causal.claims/cclara-causal-claims-ra>

- Garg, P., & Fetzer, T. (2025). Causal Claims in Economics (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2501.06873) (rep), [PDF](https://arxiv.org/pdf/2501.06873.pdf), [Google](<https://scholar.google.com/scholar?q=Causal Claims in Economics (Version 1)>).

A literature review tool grounded on the knowledge graph.

-   Search for papers by causal claims (`where X causes Y`)
-   Search for paper by concept nodes (e.g., `effects of X, causes of X`)
-   Search by claims made in specific journal (e.g. `the top five`)
-   Search by authors working on specific fields, and so on.

## About CClaRA

CClaRA is a customised GPT-4o model fine-tuned with access to our knowledge graph dataset.
This means each response is based on a combination of ChatGPT -4o 's training data and the corpus.
CClaRA searches across multiple files of structured data, ensuring that every query you make provides accurate and comprehensive results. 

训练语料：6000 多篇 NBER 和 SSRN 的工作论文，以及 Top 5 Journal 中的论文 (具体数字要看一下论文原文中的表述)

Garg, P., & Fetzer, T. (2025). Causal Claims in Economics (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2501.06873) (rep), [PDF](https://arxiv.org/pdf/2501.06873.pdf), [Google](<https://scholar.google.com/scholar?q=Causal Claims in Economics (Version 1)>).
  - [Short-Review](https://cepr.org/voxeu/columns/leveraging-large-language-models-large-scale-information-retrieval-economics)

## How to Use CClaRA

1.  Go to <https://chatgpt.com/g/g-QE4aPgEVQ-cclara> and sign in.

2.  Simply type in your query. 


## Use cases

Here are some common use cases

1.  Exact Cause and Effect Match

    -   Example Prompt: "Find papers where fiscal policy causes economic growth."

    -   This search will look for papers that contain the specified cause-effect relationship and return exact matches, if available.

2.  Cause-only Search

    -   Example Prompt: "Find papers with 'job mobility' as a cause."

    -   When only a cause is specified, the assistant will return all papers that mention this cause, along with a list of effects associated with it.

3.  Effect-only Search

    -   Example Prompt: "Find papers with 'earnings growth' as an effect."

    -   If only an effect is provided, the assistant will list papers where this effect is documented, identifying the variety of causes related to this effect.

4.  Semantic and Related Suggestions

    -   Example Prompt: "Find papers where 'government spending' influences 'GDP growth'."

    -   If an exact match isn't found, the assistant will suggest papers with related terms or semantically similar causal claims, helping to broaden the scope when needed.

5.  Combining Searches with Broadening Queries

    -   Example Prompt: "Find papers where 'education' impacts 'wage growth'."

    -   If too few results are found, the assistant may prompt you to expand the query to include related terms, such as including other measures of education or wage outcomes.

## Our Approach

Leveraging a custom Artificial Intelligence (AI) pipeline, we process vast amounts of text to extract and structure causal relationships. Here's how we build the causal graph:

1.  Data Collection: Gathering a comprehensive corpus of working papers from NBER and CEPR.

2.  AI-Powered Extraction: Using our AI model to identify causal claims, empirical methods, and key economic concepts within each paper.

3.  Standardization of Concepts: Mapping extracted variables to official Journal of Economic Literature (JEL) codes for consistency.

4.  Construction of the Causal Graph: Connecting economic concepts through identified causal relationships to form a detailed causal graph.

5.  Visualization: Creating graphical representations that illustrate how economic ideas are causally linked over time.



# B759：R扩展包介绍：disaggregation: 贝叶斯空间分解模型

Nandi, A. K., Lucas, T. C. D., Arambepola, R., Gething, P., & Weiss, D. J. (2023). disaggregation: An R Package for Bayesian Spatial Disaggregation Modeling. Journal of Statistical Software, 106(11). [Link](https://doi.org/10.18637/jss.v106.i11) (内附附件文档和代码), [PDF](https://www.jstatsoft.org/index.php/jss/article/view/v106i11/4476), [Google](<https://scholar.google.com/scholar?q=disaggregation: An R Package for Bayesian Spatial Disaggregation Modeling>).
- [Paper](https://www.jstatsoft.org/index.php/jss/article/view/v106i11/4476), [R package (disaggregation)](https://www.jstatsoft.org/index.php/jss/article/view/v106i11/4477), [Replication materials](https://www.jstatsoft.org/index.php/jss/article/view/v106i11/4478), [Replication data (mcmc\_out)](https://www.jstatsoft.org/index.php/jss/article/view/v106i11/4479)



# B758：R扩展包介绍：MLGL-层次聚类和Group-Lasso中的相关变量筛选
Grimonprez, Q., Blanck, S., Celisse, A., & Marot, G. (2023). MLGL: An R Package Implementing Correlated Variable Selection by Hierarchical Clustering and Group-Lasso. Journal of Statistical Software, 106(3). [Link](https://doi.org/10.18637/jss.v106.i03) (内附附件文档和代码), [PDF](https://www.jstatsoft.org/index.php/jss/article/view/v106i03/4443), [Google](<https://scholar.google.com/scholar?q=MLGL: An R Package Implementing Correlated Variable Selection by Hierarchical Clustering and Group-Lasso>).


# B757：2025年学术研究的9大最佳AI工具

转：[2025年学术研究的9大最佳AI工具](https://felo.ai/zh-Hant/blog/2025-best-ai-tools-academic-research/)

为了避免抄袭嫌疑，可能你需要在额外收集一些工具。从他这个清单里排除掉3~4个工具，最后形成一个新的标题，比如说 《AI 助力学术研究：推荐 15 AI 工具》

# B756：翻译-Python: Dynamic Double Machine Learning

整合如下讲义，写成 1 篇推文。

- [Dynamic Double Machine Learning](https://econml.azurewebsites.net/spec/estimation/dynamic_dml.html)

可能需要预先阅读如下资料：
- [因果推断：双重机器学习-ddml](https://www.lianxh.cn/details/1221.html)
- [DRL: Doubly Robust Learning](https://econml.azurewebsites.net/spec/estimation/dr.html)
- [DDML: Orthogonal/Double Machine Learning](https://econml.azurewebsites.net/spec/estimation/dml.html#dmluserguide)



# B755：AI-IV：如何借助大语言模型寻找IV？

- 请写一篇推文，介绍文章中提到的方法，并确保通过自己的 AI 工具进行实际测试。
- 最好使用像 Kimi 或者豆包这样的工具，因为它们的提示词和对话过程可以分享。DeepSeek 则无法分享。我个人使用的是 ChatGPT，但因为很多人没有账户，所以如果你分享的结果基于 ChatGPT，别人可能打不开。
- 最好挑选一篇最近一到两年内在国内顶级期刊（如《经济研究》或《管理世界》）上发表的论文，看看其中是否应用了工具变量法。或者，你也可以选择一个当前热门话题，在相关顶级期刊的多篇文章中发现内生性问题，然后尝试使用文章中介绍的方法寻找工具变量。你可以检验一下在这些顶刊文章已经给出的工具变量基础上，是否还能找到额外的有效工具变量。

Han, S. (2024). Mining Causality: AI-Assisted Search for Instrumental Variables (Version 2). arXiv. [Link](https://doi.org/10.48550/arXiv.2409.14202) (rep), [PDF](https://arxiv.org/pdf/2409.14202.pdf), [Google](<https://scholar.google.com/scholar?q=Mining Causality: AI-Assisted Search for Instrumental Variables (Version 2)>).

- 工具变量法（IVs）是因果推断的主流实证策略。寻找工具变量依赖研究者的创造性思维，而论证其有效性（尤其是排除性限制）常需修辞技巧。本文提出利用大语言模型（LLMs）通过叙事和反事实推理搜索新工具变量，其原理类似人类研究过程，但 LLMs 可极大加速搜索并探索海量可能性。我们设计了多步骤角色扮演提示策略，有效模拟经济主体决策逻辑并引导模型处理现实场景。方法应用于教育回报率、供需关系、同伴效应三大经典案例，并扩展至寻找回归 / 双重差分控制变量及断点设计运行变量。

There are at least four benefits to pursuing this AI-assisted approach to discovering IVs. 
- First, researchers can conduct a systematic search at a speedy rate, while adapting to the particularities of their settings. 
- Second, interacting with AI tools can inspire ideas for possible domains for novel IVs. 
- Third, the systematic search could increase the possibility of obtaining multiple IVs, which would then enable formal (i.e., statistical) testing of their validity via over-identifying restrictions. 
- Fourth, having a list of candidate IVs would increase the chances of finding actual data that contain IVs or guide the construction of such data, including the design of experiments to generate IVs.



# B754：R扩展包介绍：sparsegl: An R Package for Estimating Sparse Group Lasso

Liang, X., Cohen, A., Heinsfeld, A. S., Pestilli, F., & Mcdonald, D. J. (2024). sparsegl: An R Package for Estimating Sparse Group Lasso. Journal of Statistical Software, 110(6). [Link](https://doi.org/10.18637/jss.v110.i06) (内附附件文档和代码), [PDF](https://www.jstatsoft.org/index.php/jss/article/view/v110i06/4608), [Google](<https://scholar.google.com/scholar?q=sparsegl: An R Package for Estimating Sparse Group Lasso>).

-  [Paper](https://www.jstatsoft.org/index.php/jss/article/view/v110i06/4608) [R package (sparsegl)](https://www.jstatsoft.org/index.php/jss/article/view/v110i06/4609) [R replication code](https://www.jstatsoft.org/index.php/jss/article/view/v110i06/4610)

# B753：R扩展包介绍：fairadapt: Causal Reasoning for Fair Data Preprocessing
Plecko, D., Bennett, N., & Meinshausen, N. (2024). fairadapt: Causal Reasoning for Fair Data Preprocessing. Journal of Statistical Software, 110(4). [Link](https://doi.org/10.18637/jss.v110.i04) (内附附件文档和代码), [PDF](https://www.jstatsoft.org/index.php/jss/article/view/v110i04/4614), [Google](<https://scholar.google.com/scholar?q=fairadapt: Causal Reasoning for Fair Data Preprocessing>).


# B752：论文推介：安慰剂检验

Eggers, A. C., Tu?ón, G., & Dafoe, A. (**2024**). Placebo Tests for Causal Inference. American Journal of Political Science, 68(3), 1106–1121. Portico. [Link](https://doi.org/10.1111/ajps.12818), [HTML](https://onlinelibrary.wiley.com/doi/full/10.1111/ajps.12818), [PDF](https://onlinelibrary.wiley.com/doi/epdf/10.1111/ajps.12818), [Google](<https://scholar.google.com/scholar?q=Placebo Tests for Causal Inference. American Journal of Political Science, 68(3), 1106–1121>). [-Replication-](https://doi.org/10.7910/DVN/3RR5RJ)

提纲：
- 安慰剂检验在实证分析中的应用趋势
- 何谓安慰剂检验？
- 基本假设
- 典型案例。找几篇论文，简要介绍几种典型的安慰剂检验套路
- Check list
- 小结
  
## Check list

作为总结，我们提供了一份适用于任何安慰剂检验的问题清单。正如"我们能从安慰剂检验中学到什么？"所述，关于安慰剂检验的核心问题是："当某些核心假设以特定方式被违反时，检验结果是否比假设成立时更可能失败？"这个问题可分解为以下检查清单：

1. 检验探测了哪些核心假设——与点估计相关的偏差假设（识别、估计、测量、样本选择）或与标准误相关的分布假设？（见"信息性安慰剂检验的形式条件"）

2. 哪些核心假设的潜在违反情况最为相关？（见"我们能从安慰剂检验中学到什么？"）

3. 构建安慰剂检验时，对核心分析的哪个组成部分（结果变量、处理变量、研究群体）进行了调整？（见"安慰剂检验的分类"）

4. 为何在这种调整下，处理变量应对安慰剂分析中的结果变量无影响？（NATE，见"信息性安慰剂检验的形式条件"）

5. 安慰剂分析与核心分析在哪些方面具有相似性，从而能够检测核心假设的违反？（LVBA/LVDA，见"信息性安慰剂检验的形式条件"）

6. 安慰剂分析是否可能存在核心分析中未出现的假设违反，导致假阳性率上升？（LBA/LDA，见"信息性安慰剂检验的形式条件"）

7. 安慰剂检验是否具备足够的统计精度（如通过标准误判断）来检测核心假设的违反？（见"我们能从安慰剂检验中学到什么？"）

每个问题均标注了正式框架中的对应章节，这些问题也贯穿于"偏差假设的安慰剂检验设计"和"分布假设的安慰剂检验设计"的案例讨论。如果读者在遇到安慰剂检验时能经常自问这些问题，而研究者在报告检验结果时能提供足够的信息来回答它们，那么安慰剂检验将更好地帮助评估应用因果推断中研究设计的可信度。

（注：NATE = 平均处理效应为零；LVBA = 局部效度偏差假设；LVDA = 局部效度分布假设；LBA = 局部偏差假设；LDA = 局部分布假设）


# B751：Judea Pearl 聊 AI 的未来：我们需要因果AI

根据下面的推文，还有视频来整理一篇推文。尽量原汁原味的反映 Pearl 教授的观点。

> Judea Pearl on the Future of AI, LLMs, and Need for Causal Reasoning, [-Link-](https://causalai.causalens.com/resources/blog/judea-pearl-on-the-future-of-ai-llms-and-need-for-causal-reasoning/), [Vedio](https://player.vimeo.com/video/969883388)

<div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/969883388?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture; clipboard-write" style="position:absolute;top:0;left:0;width:100%;height:100%;" title="Session 4 CAI SF - A Fireside Chat with Judea Pearl and Darko Matovski"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

>This transcript has been lightly edited for length and clarity.


# B750：遗漏变量？敏感性分析！新命令sensemakr-R codes

此前，连享会已经发布了该命令的 Stata 版本的介绍 (邹恬华, 2021, [遗漏变量？敏感性分析！新命令sensemakr](https://www.lianxh.cn/details/621.html))。这篇推文则提供基于 R codes 的范例。在作者正式发表的版本中，对 R codes 的介绍非常细致，还包含了高级用法以及 Appendix B. Interaction and Bootstrap Example 等例子。

- Cinelli, C., Ferwerda, J., & Hazlett, C. (2024). Sensemakr: Sensitivity Analysis Tools for OLS in R and Stata. Observational Studies, 10(2), 93–127. [Link](https://doi.org/10.1353/obs.2024.a946583), [PDF](https://muse.jhu.edu/pub/56/article/946583/pdf), [Google](<https://scholar.google.com/scholar?q=Sensemakr: Sensitivity Analysis Tools for OLS in R and Stata>).

提纲：
- 敏感性分析的思路、使用背景等
- 基本理论分析
- R 实操
- 进阶应用
- Interaction and Bootstrap Example
- 结论


# B749：敏感性分析：实操手册

Prasad, S. K., Kastel, F., Pande, S., Zhang, C., & Glandon, D. M. (2024). A checklist to guide sensitivity analyses and replications of impact evaluations. Journal of Development Effectiveness, 16(3), 332–348. [Link](https://doi.org/10.1080/19439342.2024.2318695), [PDF](https://www.tandfonline.com/doi/epdf/10.1080/19439342.2024.2318695%4010.1080/tfocoll.2024.0.issue-special-issue-on-tree?needAccess=true), [Google](<https://scholar.google.com/scholar?q=A checklist to guide sensitivity analyses and replications of impact evaluations>). [-Appendix-Word](https://www.tandfonline.com/doi/suppl/10.1080/19439342.2024.2318695%4010.1080/tfocoll.2024.0.issue-special-issue-on-tree?scroll=top)

Note: 
- 这篇论文除了正文的内容以外，附录的内容也不错，但是我还没有细看，你自己读完以后来决定是否把正文和附录的内容合并起来。如果两部分的内容有比较明显的差别，各自都有各自的价值，那就可以把它们拆成两篇推文来写，算两个工作量。
- 我用豆包把 [-Appendix-Word](https://www.tandfonline.com/doi/suppl/10.1080/19439342.2024.2318695%4010.1080/tfocoll.2024.0.issue-special-issue-on-tree?scroll=top) 中的内容转换成了马当格式，但是里边的参考文献尤其是参考文献的链接没有很好的处理，你可以继续用其他的ai工具来完成这个任务，或者自己使用 [getiref](https://www.lianxh.cn/details/1382.html) 命令来补充进去。


# B748：翻译-IPW - 面板数据因果推断中的逆概率加权

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- Heiss, Andrew. 2020. “Generating Inverse Probability Weights for Marginal Structural Models with Time-Series Cross-Sectional Panel Data.” December 3, 2020. https://doi.org/10.59350/48w1z-xen07.


# B747：翻译-IPW - 二元和连续处理效应的逆概率加权

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- Heiss, Andrew. 2020. “Generating Inverse Probability Weights for Both Binary and Continuous Treatments.” December 1, 2020. https://doi.org/10.59350/1svkc-rkv91.


# B746：翻译-R2 - 韦恩图直观解读

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- Heiss, Andrew. 2021. “Exploring R2 and Regression Variance with Euler/Venn Diagrams.” August 21, 2021. https://doi.org/10.59350/t57vy-p5115.

>Note: 点击主页面右上角的 `</> code` 按钮即可复制原文 Markdown 格式文件，在此基础上运行 R 代码，翻译即可。


# B745：翻译：用 R 绘制供给需求曲线

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。

- Heiss, Andrew. 2017. Create supply and demand economics curves with ggplot2. [Link](https://www.andrewheiss.com/blog/2017/09/15/create-supply-and-demand-economics-curves-with-ggplot2/)


# B744：翻译：ATE, ATT, and ATU

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- Heiss, Andrew. 2024. “Demystifying Causal Inference Estimands: ATE, ATT, and ATU.” March 21, 2024. [-Link-](https://www.andrewheiss.com/blog/2024/03/21/demystifying-ate-att-atu/), https://doi.org/10.59350/c9z3a-rcq16.
  - 这篇推文对理解因果推断基本概念，尤其是逆概率加权非常有帮助

>Note: 点击主页面右上角的 `</> code` 按钮即可复制原文 Markdown 格式文件，在此基础上运行 R 代码，翻译即可。


# B743：翻译：贝叶斯逆概率加权

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- Heiss, Andrew. 2021. “How to Use Bayesian Propensity Scores and Inverse Probability Weights.” December 18, 2021. [-Link-](https://doi.org/10.59350/nrwsd-3jz20)

>Note: 点击主页面右上角的 `</> code` 按钮即可复制原文 Markdown 格式文件，在此基础上运行 R 代码，翻译即可。


# B742：翻译：零膨胀模型 - R 解读

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- Heiss, Andrew. 2022. “A Guide to Modeling Outcomes That Have Lots of Zeros with Bayesian Hurdle Lognormal and Hurdle Gaussian Regression Models.” May 9, 2022. https://doi.org/10.59350/ety2j-09566. [-Link-](https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/)

>Note: 点击主页面右上角的 `</> code` 按钮即可复制原文 Markdown 格式文件，在此基础上运行 R 代码，翻译即可。


# B741：翻译：被解释变量是比率时如何估计？

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- Heiss, Andrew. 2021. “A Guide to Modeling Proportions with Bayesian Beta and Zero-Inflated Beta Regression Models.” November 8, 2021. https://doi.org/10.59350/7p1a4-0tw75. [-Link-](https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/)

>Note: 点击主页面右上角的 `</> code` 按钮即可复制原文 Markdown 格式文件，在此基础上运行 R 代码，翻译即可。

![20250322004357](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250322004357.png)


# B740：翻译：因果推断之后门法则详解

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- Heiss, Andrew. 2021. “Do-Calculus Adventures! Exploring the Three Rules of Do-Calculus in Plain Language and Deriving the Backdoor Adjustment Formula by Hand.” September 7, 2021. [-Link-](https://doi.org/10.59350/fqkhz-kq526).

>Note: 点击主页面右上角的 `</> code` 按钮即可复制原文 Markdown 格式文件，在此基础上运行 R 代码，翻译即可。


# B739：翻译：R 常用数据处理函数可视化解读

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- [Visualizing {dplyr}’s mutate(), summarize(), group_by(), and ungroup() with animations](https://www.andrewheiss.com/blog/2024/04/04/group_by-summarize-ungroup-animations/)

>Note: 点击主页面右上角的 `</> code` 按钮即可复制原文 Markdown 格式文件，在此基础上运行 R 代码，翻译即可。


# B738：quarto 模板介绍

写一篇推文，介绍 Quarto 模版的使用和下载方法。

提供几个可以下载 Quarto 论文或讲义模板的网址，展示其使用方法和效果。例如：
- [Hikmah Quarto templates](https://github.com/andrewheiss/hikmah-academic-quarto)


# B737：全新集成编辑器：Positron

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。

- [Fun with Positron: Combine the best of RStudio and Visual Studio Code in Posit’s new Positron IDE](https://www.andrewheiss.com/blog/2024/07/08/fun-with-positron/)


# B736：翻译 What to do with age? Linear, Discrete, Both, or Spline

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- <https://arelbundock.com/posts/age_linear_discrete/age_linear_discrete.html>
- 类似于时间趋势和时间虚拟变量那篇。参见此前连享会的推文：
  - 徐婷, 徐云娇, 2020, [傻傻分不清：时间趋势项与时间虚拟变量](https://www.lianxh.cn/details/147.html), 连享会 No.147.
- [What to do with age? (including a regression predictor linearly and also in discrete steps)](https://statmodeling.stat.columbia.edu/2024/06/19/what/)


# B735：翻译+补充-marginalia：边际效应详解

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  

https://www.andrewheiss.com/blog/2022/05/20/marginalia/

如果太长，可以拆成 2-3 篇推文


# B734：G-computation

从 [The causal cookbook: Recipes for propensity scores, g-computation, and doubly robust standardization](https://journals.sagepub.com/doi/abs/10.1177/25152459241236149) 中抽取内容，再借助 DeepSeek，ChatGPT，豆包等工具完成写作。

> **Box 5**. G-Computation Recipe

Ingredients: Action $A$, outcome $Y$, and controls $C$.

Important: For an unbiased estimate, the controls $C$ must be sufficient to achieve conditional exchangeability.

- **Step 1**: Model the outcome as $\mathrm{Q}(\mathrm{A}, \mathrm{C})$, a function of the controls. For example, this could be a logistic regression predicting $Y$ from $A$ and $C$, using all individuals in the sample.
- **Step 2**: Duplicate the initial data set in two counterfactual data sets. In one of them, set $A=1$; in the other one, set $A=0$.
All other variables keep their original values.
- **Step 3**: Apply the function $\mathrm{Q}(\mathrm{A}, \mathrm{C})$ to predict each individual's outcome in the two counterfactual data sets; these are the model-implied potential outcomes $Y^1$ and $Y^0$.
- **Step 4**: Aggregate these potential outcomes (e.g., average across all individuals) and contrast them (e.g., by taking their difference) to arrive at an estimate of the estimand of interest.
  
Examples of R packages implementing this estimator: `marginaleffects`, `RISCA`, `stdReg`.


# B733：翻译+扩充：Equivalence Tests Using marginaleffects

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
Reproducing the Clark and Golder (2006) Example from Rainey (2014)

- <https://www.carlislerainey.com/blog/2023-08-18-equivalence-tests/>

有关 `marginaleffect` 的更详细的介绍参见：

Arel-Bundock, V., Greifer, N., & Heiss, A. (2024). How to Interpret Statistical Models Using marginaleffects for R and Python. Journal of Statistical Software, 111(9). [Link](https://doi.org/10.18637/jss.v111.i09) (内附复现文档和详细说明), [PDF](https://www.jstatsoft.org/index.php/jss/article/view/v111i09/4641), [Google](<https://scholar.google.com/scholar?q=How to Interpret Statistical Models Using marginaleffects for R and Python>). [marginaleffects.com](https://marginaleffects.com/)



# B732：R语言扩展包：边际效应-marginaleffects

Arel-Bundock, V., Greifer, N., & Heiss, A. (2024). How to Interpret Statistical Models Using marginaleffects for R and Python. Journal of Statistical Software, 111(9). [Link](https://doi.org/10.18637/jss.v111.i09) (内附复现文档和详细说明), [PDF](https://www.jstatsoft.org/index.php/jss/article/view/v111i09/4641), [Google](<https://scholar.google.com/scholar?q=How to Interpret Statistical Models Using marginaleffects for R and Python>). [marginaleffects.com](https://marginaleffects.com/)


# B731：Stata - sumdocx 命令介绍

写一篇推文介绍 `sumdocx` 命令的使用方法。建议使用 Stata 自带的数据集 **nlsw88.dta** 来演示。输出的结果尽量用代码块的方式来呈现，有一些结果如果是以word的形式输出的，可以采用截图来呈现。

帮助文件提供了许多例子，展示了 `sumdocx` 命令的多种灵活用法。我们写这篇推文的目的是为了帮助大家在写论文时，能够直接使用现有代码生成符合期刊格式要求的表格，而不仅仅是介绍命令的基本用法（这部分可以通过帮助文件自学）。我们的价值在于提供实际应用的示范，帮助大家实现期刊格式的输出。

因此，请根据这个思路，调整并优化示例代码，适当增加复杂度，确保输出的表格与我们投稿的期刊格式一致。

> 你可以在 [我的提示词](https://chatgpt.com/share/67f0af5c-4af4-8005-a5ea-d45728e500d8) 基础上做进一步的修改，增加其他方面的提示，不断的完善和优化这篇推文。

下面是ai自动输出的一个推文的初稿，你可以在里边添加一些解释性的文字，尤其重要的是矫正里边的代码是否正确在自己的电脑上运行完以后，把输出的结果插入推文。尤其是一些word表格格式输出的结果一定要采用清晰的截图插入推文。

> [B731-sum2docx.md](https://gitee.com/Stata002/StataSX2018/blob/master/sample/B731-sum2docx.md)

用法：点击「编辑」按钮即可查看原文。 


# B730：Power analyses for interaction effects

- Baranger, D. A., Finsaas, M., Goldstein, B., Vize, C., Lynam, D., & Olino, T. M. (2022). Tutorial: Power analyses for interaction effects in cross-sectional regressions. [Link](https://doi.org/10.31234/osf.io/5ptd7), [PDF](http://sci-hub.ren/10.31234/osf.io/5ptd7), [Google](<https://scholar.google.com/scholar?q=>).
  - Code and material availability Expanded hyperlinks are available in Supplemental Table 1. The InteractionPoweR R package is freely available for download at: 
    - https://cran.r-project.org/web/packages/InteractionPoweR/index.html
    - https://dbaranger.github.io/InteractionPoweR/. 
- Underlying code is available at: https://github.com/dbaranger/InteractionPoweR. 
- The interactive Shiny App for simulations is available at: https://mfinsaas.shinyapps.io/InteractionPoweR/.
-  The interactive Shiny App for analytic power is available at: https://david-baranger.shinyapps.io/InteractionPoweR analytic/. 
-  The R software environment is freely available at: https://www.r-project.org/. 
-  RStudio is freely available at: https://www.rstudio.com/products/rstudio/. The code used in this tutorial is available in the Supplement.


# B729：论文复现及推介：平方项的使用

Lee, C.-C., Yuan, Z., He, Z.-W., & Xiao, F. (2024). Do geopolitical risks always harm energy security? Their non-linear effects and mechanism. Energy Economics, 129, 107245. [Link](https://doi.org/10.1016/j.eneco.2023.107245) (rep), [PDF](https://file-lianxh.oss-cn-shenzhen.aliyuncs.com/Refs/refs_common/Lee_2024_Do_geopolitical_risks_always_harm_energy_security_U_shape.pdf), [Google](<https://scholar.google.com/scholar?q=Do geopolitical risks always harm energy security? Their non-linear effects and mechanism>), [-Replication-](https://ars.els-cdn.com/content/image/1-s2.0-S0140988323007430-mmc1.zip)


# B728：论文推介：Large Language Models and Sentiment Analysis in Financial Markets

Liu, C., Arulappan, A., Naha, R., Mahanti, A., Kamruzzaman, J., & Ra, I.-H. (2024). Large Language Models and Sentiment Analysis in Financial Markets: A Review, Datasets, and Case Study. IEEE Access, 12, 134041–134061. [Link](https://doi.org/10.1109/ACCESS.2024.3445413), [PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10638546), [Google](<https://scholar.google.com/scholar?q=Large Language Models and Sentiment Analysis in Financial Markets: A Review, Datasets, and Case Study>).

开始写作之前请先列一个提纲，然后找我讨论。这篇推文的主要目的是介绍大型模型在文本分析里边的一些主要的方法；如何借助ai工具展开此类的分析，以及文中提到的一些典型的数据库。

推文写作过程中可以借助 ai 工具。

比如，我之前写另外一篇推文时的提示词可以参考：[BGATE 模型：ChatGPT 提示词-论文解读](https://chatgpt.com/share/67f0a7d3-cbcc-8005-857d-bbcfe4e680cd)


# B727：交乘项的中心化问题

How to tell when interaction estimates will benefit from centering.

- Olvera Astivia, O. L., & Kroc, E. (2019). Centering in Multiple Regression Does Not Always Reduce Multicollinearity: How to Tell When Your Estimates Will Not Benefit From Centering. Educational and Psychological Measurement, 79(5), 813–826. [Link](https://doi.org/10.1177/0013164418817801), [PDF](http://sci-hub.ren/10.1177/0013164418817801), [Google](<https://scholar.google.com/scholar?q=Centering in Multiple Regression Does Not Always Reduce Multicollinearity: How to Tell When Your Estimates Will Not Benefit From Centering>).


# B726：DDD综述及应用文献整理

> Olden, A., & M?en, J. (2022). The triple difference estimator. The Econometrics Journal, 25(3), 531–553. [Link](https://doi.org/10.1093/ectj/utac010), [PDF](https://www.liuyanecon.com/wp-content/uploads/OldenMoen-2022.pdf), [Google](<https://scholar.google.com/scholar?q=The triple difference estimator>).

任务说明：
1. 介绍 DDD 的基本思想、适用场景和估计方法
2. 最重要的是：总结 Table A1，梳理出使用 DDD 的经典文献。可以使用 [getiref]() 命令或 DeepSeek, ChatGPT 等 AI 工具辅助生成参考文献信息，格式为：Olden, A., & M?en, J. (2022). The triple difference estimator. The Econometrics Journal, 25(3), 531–553. [Link](https://doi.org/10.1093/ectj/utac010), [PDF](http://sci-hub.ren/10.1093/ectj/utac010), [Google](<https://scholar.google.com/scholar?q=The triple difference estimator>).
3. 如果内容太多，可以拆成两篇推文，算作两个工作任务。 


# B725：论文推介：你到底在估计什么？

Lundberg, I., Johnson, R., & Stewart, B. M. (2021). What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory. American Sociological Review, 86(3), 532–565. [Link](https://doi.org/10.1177/00031224211004187), [PDF](http://sci-hub.ren/10.1177/00031224211004187), [Google](<https://scholar.google.com/scholar?q=What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory>), [-Replication-](https://doi.org/10.7910/DVN/ASGOVU)

- **Abstract**: We make only one point in this article. Every quantitative study must be able to answer the question: what is your estimand? The estimand is the target quantity-the purpose of the statistical analysis. Much attention is already placed on how to do estimation; a similar degree of care should be given to defining the thing we are estimating. We advocate that authors state the central quantity of each analysis-the theoretical estimand-in precise terms that exist outside of any statistical model. In our framework, researchers do three things: (1) set a theoretical estimand, clearly connecting this quantity to theory; (2) link to an empirical estimand, which is informative about the theoretical estimand under some identification assumptions; and
(3) learn from data. Adding precise estimands to research practice expands the space of theoretical questions, clarifies how evidence can speak to those questions, and unlocks new tools for estimation. By grounding all three steps in a precise statement of the target quantity, our framework connects statistical evidence to theory.


# B724：文本分析 - LDA 模型实操建议

基于如下资料，写一篇推文介绍 LDA 模型。文中的一些细节可以借助 DeepSeek，ChatGPT 等工具来补充和完善。 

Kulshrestha, R., 2019, A Beginner’s Guide to Latent Dirichlet Allocation(LDA): A statistical model for discovering the abstract topics aka topic modeling. [-Link-](https://towardsdatascience.com/latent-dirichlet-allocation-lda-9d1cd064ffa2)


# B723-空间计量-莫兰指数-moransi-空间自相关检验

任务：以如下论文为基础，写一篇推文介绍这个检验方法和 stata 的实现。

- Kondo, Keisuke (2025) "Testing for Spatial Autocorrelation in Stata," RIEB Discussion Paper Series No.2025-03. [-PDF-](https://www.rieb.kobe-u.ac.jp/academic/ra/dp/English/DP2025-03.pdf), [github](https://github.com/keisukekondokk/moransi)

## 简介
The `moransi` command computes global and local Moran's *I* statistics in Stata.

简要说明一下前期相关推文：

  - 陈子厚, 2022, [Matlab：莫兰指数的编程实现](https://www.lianxh.cn/details/1085.html), 连享会 No.1085.
  - 陈子厚, 2021, [Stata：面板数据的莫兰指数计算与散点图绘制-xtmoran](https://www.lianxh.cn/details/778.html), 连享会 No.778.
  - 陈振环, 张少鹏, 2021, [Stata空间计量：莫兰指数绘图moranplot命令介绍](https://www.lianxh.cn/details/729.html), 连享会 No.729.
 
## Stata 实操
### SSC 安装

```stata
ssc install moransi, replace all

shellout moransi.pdf  // PDF 原文

help moransi
```

### Demo Files

See three applied examples in [`demo`](https://github.com/keisukekondokk/moransi/blob/main/demo) directory.

```
.
|-- columbus //Stata replication code and data
|-- japan\_mesh\_pop //Stata replication code and data
|-- japan\_muni\_unemp //Stata replication code and data
```

## Reference

- Kondo, Keisuke (2018) "MORANSI: Stata module to compute Moran's *I*," Statistical Software Components S458473, Boston College Department of Economics.
URL: <https://ideas.repec.org/c/boc/bocode/s458473.html>
- Kondo, Keisuke (2025) "Testing for Spatial Autocorrelation in Stata," RIEB Discussion Paper Series No.2025-03.
URL: <https://www.rieb.kobe-u.ac.jp/academic/ra/dp/English/DP2025-03.pdf>


# B722-翻译-论文推介：实证分析常见错误指南

- Wulff, J. N., Sajons, G. B., Pogrebna, G., Lonati, S., Bastardoz, N., Banks, G. C., & Antonakis, J. (2023). Common methodological mistakes. The Leadership Quarterly, 34(1), 101677. [Link](https://doi.org/10.1016/j.leaqua.2023.101677), [PDF](http://sci-hub.ren/10.1016/j.leaqua.2023.101677), [Google](<https://scholar.google.com/scholar?q=Common methodological mistakes>).

写作要点：
- 第一篇推文：整理 Table 1: Common Issues in Empirical Articles and Suggested Solutions. 我已经整理成 items 形式，并使用 ChatGPT 进行了翻译，你可以酌情调整即可。
  - [Table1-英文版](https://gitee.com/Stata002/StataSX2018/blob/master/sample/B722-Common-mistakes.md) | [Table1-中文版](https://gitee.com/Stata002/StataSX2018/blob/master/sample/B722-Common-mistakes-Chinese.md)
- 第二篇推文：对这篇论文的后半部分进行翻译。这些内容为实证分析中的常见错误都提供了解决方法。你可以借助ai的工具进行翻译，我发现一个简单的办法就是你直接把作者原始提供的 pdf 文件的截图给DeepSeek 或者是 ChatGPT，他就可以一页一页的帮你翻译完了。当然你如果能找到更好的办法，那也行。要注意的是，如果你直接把整个pdf传给ai，他会帮你删掉很多内容。